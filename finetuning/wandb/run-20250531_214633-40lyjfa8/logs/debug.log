2025-05-31 21:46:33,960 INFO    MainThread:443766 [wandb_setup.py:_flush():70] Current SDK version is 0.19.11
2025-05-31 21:46:33,960 INFO    MainThread:443766 [wandb_setup.py:_flush():70] Configure stats pid to 443766
2025-05-31 21:46:33,960 INFO    MainThread:443766 [wandb_setup.py:_flush():70] Loading settings from /home/yuexi/.config/wandb/settings
2025-05-31 21:46:33,961 INFO    MainThread:443766 [wandb_setup.py:_flush():70] Loading settings from /home/yuexi/codegeneration/finetuning/wandb/settings
2025-05-31 21:46:33,961 INFO    MainThread:443766 [wandb_setup.py:_flush():70] Loading settings from environment variables
2025-05-31 21:46:33,961 INFO    MainThread:443766 [wandb_init.py:setup_run_log_directory():724] Logging user logs to /home/yuexi/codegeneration/finetuning/wandb/run-20250531_214633-40lyjfa8/logs/debug.log
2025-05-31 21:46:33,962 INFO    MainThread:443766 [wandb_init.py:setup_run_log_directory():725] Logging internal logs to /home/yuexi/codegeneration/finetuning/wandb/run-20250531_214633-40lyjfa8/logs/debug-internal.log
2025-05-31 21:46:33,962 INFO    MainThread:443766 [wandb_init.py:init():852] calling init triggers
2025-05-31 21:46:33,963 INFO    MainThread:443766 [wandb_init.py:init():857] wandb.init called with sweep_config: {}
config: {'model': ModelConfig(model_name='codellama/CodeLlama-7b-Python-hf', use_4bit=True, bnb_4bit_compute_dtype='float16', bnb_4bit_quant_type='nf4', use_nested_quant=False, lora_r=64, lora_alpha=16, lora_dropout=0.1, lora_target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'], max_seq_length=1024, trust_remote_code=True), 'data': DataConfig(dataset_name='mbpp', max_prompt_length=512, max_completion_length=512, train_test_split=0.9, num_proc=4), 'training': TrainingConfig(output_dir='./checkpoints/ppo-qlora', per_device_train_batch_size=12, per_device_eval_batch_size=12, gradient_accumulation_steps=1, num_train_epochs=2, learning_rate=3e-06, lr_scheduler_type='cosine', warmup_ratio=0.05, weight_decay=0.01, max_grad_norm=0.5, eval_steps=250, logging_steps=5, save_steps=250, save_total_limit=5, load_best_model_at_end=True, metric_for_best_model='eval_test_pass_rate', greater_is_better=True, ppo_epochs=2, mini_batch_size=1, vf_coef=0.3, cliprange=0.15, cliprange_value=0.15, gamma=1.0, lam=0.95, target_kl=0.5, grpo_alpha=10.0, max_new_tokens=256, do_sample=True, temperature=0.7, top_p=0.9, reward_model_path=None, code_execution_timeout=10.0), 'hf': HuggingFaceConfig(hub_model_id='codellama-7b-mbpp-ppo-qlora', hub_token=None, push_to_hub=True, hub_private_repo=False, hub_strategy='every_save'), 'seed': 42, 'method': 'ppo', 'use_wandb': True, 'wandb_project': 'codellama-mbpp-finetuning', 'wandb_run_name': 'codellama-7b-ppo-qlora', '_wandb': {}}
2025-05-31 21:46:33,963 INFO    MainThread:443766 [wandb_init.py:init():893] starting backend
2025-05-31 21:46:33,963 INFO    MainThread:443766 [wandb_init.py:init():897] sending inform_init request
2025-05-31 21:46:33,970 INFO    MainThread:443766 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-05-31 21:46:33,970 INFO    MainThread:443766 [wandb_init.py:init():907] backend started and connected
2025-05-31 21:46:33,974 INFO    MainThread:443766 [wandb_init.py:init():1005] updated telemetry
2025-05-31 21:46:33,975 INFO    MainThread:443766 [wandb_init.py:init():1029] communicating run to backend with 90.0 second timeout
2025-05-31 21:46:34,307 INFO    MainThread:443766 [wandb_init.py:init():1104] starting run threads in backend
2025-05-31 21:46:34,696 INFO    MainThread:443766 [wandb_run.py:_console_start():2573] atexit reg
2025-05-31 21:46:34,696 INFO    MainThread:443766 [wandb_run.py:_redirect():2421] redirect: wrap_raw
2025-05-31 21:46:34,697 INFO    MainThread:443766 [wandb_run.py:_redirect():2490] Wrapping output streams.
2025-05-31 21:46:34,697 INFO    MainThread:443766 [wandb_run.py:_redirect():2513] Redirects installed.
2025-05-31 21:46:34,702 INFO    MainThread:443766 [wandb_init.py:init():1150] run started, returning control to user process
